{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Create TensorFlow model </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating a model using the high-level Estimator API \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'qwiklabs-gcp-03-042231f997f5'\n",
    "PROJECT = '003-model-dnn'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Create TensorFlow model using TensorFlow's Estimator API </h2>\n",
    "<p>\n",
    "First, write an input_fn to read the data.\n",
    "<p>\n",
    "\n",
    "## Lab Task 1\n",
    "Verify that the headers match your CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Determine CSV, label, and key columns\n",
    "CSV_COLUMNS = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks,key'.split(',')\n",
    "LABEL_COLUMN = 'weight_pounds'\n",
    "KEY_COLUMN = 'key'\n",
    "\n",
    "# Set default values for each CSV column\n",
    "DEFAULTS = [[0.0], ['null'], [0.0], ['null'], [0.0], ['nokey']]\n",
    "TRAIN_STEPS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lab Task 2\n",
    "\n",
    "Fill out the details of the input function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "  def _input_fn():\n",
    "    def decode_csv(value_column):\n",
    "      # TODO #1: Use tf.decode_csv to parse the provided line\n",
    "      columns = tf.io.decode_csv(value_column, record_defaults = DEFAULTS)\n",
    "      # TODO #2: Make a Python dict.  The keys are the column names, the values are from the parsed data\n",
    "      features = dict(zip(CSV_COLUMNS, columns))\n",
    "      # TODO #3: Return a tuple of features, label where features is a Python dict and label a float\n",
    "      label = features.pop(LABEL_COLUMN)\n",
    "      return features, label\n",
    "    \n",
    "    # TODO #4: Use tf.gfile.Glob to create list of files that match pattern\n",
    "    file_list = tf.io.gfile.glob(filename)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = (tf.data.TextLineDataset(file_list)  # Read text file\n",
    "                 .map(decode_csv))  # Transform each elem by applying decode_csv fn\n",
    "    \n",
    "    # TODO #5: In training mode, shuffle the dataset and repeat indefinitely\n",
    "    #                (Look at the API for tf.data.dataset shuffle)\n",
    "    #          The mode input variable will be tf.estimator.ModeKeys.TRAIN if in training mode\n",
    "    #          Tell the dataset to provide data in batches of batch_size \n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        num_epochs = None # indefinitely\n",
    "        dataset = dataset.shuffle(buffer_size = 10*batch_size)\n",
    "    else:\n",
    "        num_epochs = 1 # end-of-input after this\n",
    "        \n",
    "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "    # This will now return batches of features, label\n",
    "    return dataset\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lab Task 3\n",
    "\n",
    "Use the TensorFlow feature column API to define appropriate feature columns for your raw features that come from the CSV.\n",
    "\n",
    "<b> Bonus: </b> Separate your columns into wide columns (categorical, discrete, etc.) and deep columns (numeric, embedding, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "def get_categorical(name, values):\n",
    "  return tf.feature_column.indicator_column(\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(name, values))\n",
    "\n",
    "def get_cols():\n",
    "  # Define column types\n",
    "  return [\\\n",
    "          get_categorical('is_male', ['True', 'False', 'Unknown']),\n",
    "          tf.feature_column.numeric_column('mother_age'),\n",
    "          get_categorical('plurality',\n",
    "                      ['Single(1)', 'Twins(2)', 'Triplets(3)',\n",
    "                       'Quadruplets(4)', 'Quintuplets(5)','Multiple(2+)']),\n",
    "          tf.feature_column.numeric_column('gestation_weeks')\n",
    "      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lab Task 4\n",
    "\n",
    "To predict with the TensorFlow model, we also need a serving input function (we'll use this in a later lab). We will want all the inputs from our user.\n",
    "\n",
    "Verify and change the column names and types here as appropriate. These should match your CSV_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create serving input function to be able to serve predictions later using provided inputs\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'is_male': tf.compat.v1.placeholder(tf.string, [None]),\n",
    "        'mother_age': tf.compat.v1.placeholder(tf.float32, [None]),\n",
    "        'plurality': tf.compat.v1.placeholder(tf.string, [None]),\n",
    "        'gestation_weeks': tf.compat.v1.placeholder(tf.float32, [None])\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lab Task 5\n",
    "\n",
    "Complete the TODOs in this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create estimator to train and evaluate\n",
    "def train_and_evaluate(output_dir):\n",
    "  EVAL_INTERVAL = 300\n",
    "  run_config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL,\n",
    "                                      keep_checkpoint_max = 3)\n",
    "  # TODO #1: Create your estimator\n",
    "  estimator = tf.estimator.DNNRegressor(\n",
    "                       model_dir = output_dir,\n",
    "                       feature_columns = get_cols(),\n",
    "                       hidden_units = [64, 32],\n",
    "                       config = run_config)\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "                       # TODO #2: Call read_dataset passing in the training CSV file and the appropriate mode\n",
    "                       input_fn = read_dataset('train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
    "                       max_steps = TRAIN_STEPS)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(\n",
    "                       # TODO #3: Call read_dataset passing in the evaluation CSV file and the appropriate mode\n",
    "                       input_fn = read_dataset('eval.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 60, # start evaluating after N seconds\n",
    "                       throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'babyweight_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adagrad.py:103: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into babyweight_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 68.90766, step = 0\n",
      "INFO:tensorflow:global_step/sec: 32.2212\n",
      "INFO:tensorflow:loss = 1.5162146, step = 100 (3.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.965\n",
      "INFO:tensorflow:loss = 1.3566742, step = 200 (2.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4887\n",
      "INFO:tensorflow:loss = 1.3725116, step = 300 (3.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7053\n",
      "INFO:tensorflow:loss = 1.1601167, step = 400 (3.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0063\n",
      "INFO:tensorflow:loss = 1.1089344, step = 500 (3.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5668\n",
      "INFO:tensorflow:loss = 1.1955028, step = 600 (3.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8615\n",
      "INFO:tensorflow:loss = 1.139163, step = 700 (3.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5167\n",
      "INFO:tensorflow:loss = 1.2576401, step = 800 (3.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2056\n",
      "INFO:tensorflow:loss = 1.3394877, step = 900 (3.817 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into babyweight_trained/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-03T02:15:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.20763s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-03-02:15:42\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.2412107, global_step = 1000, label/mean = 7.2368712, loss = 1.2421752, prediction/mean = 7.2553983\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'is_male': <tf.Tensor 'Placeholder:0' shape=(None,) dtype=string>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(None,) dtype=float32>, 'plurality': <tf.Tensor 'Placeholder_2:0' shape=(None,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(None,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'is_male': <tf.Tensor 'Placeholder:0' shape=(None,) dtype=string>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(None,) dtype=float32>, 'plurality': <tf.Tensor 'Placeholder_2:0' shape=(None,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(None,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: babyweight_trained/export/exporter/temp-b'1588472142'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 1.2563323.\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "shutil.rmtree('babyweight_trained', ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate('babyweight_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
